---
title: 工程实践中遇到的排序算法
toc: true
thumbnail: /images/starbuck.jpeg
date: 2019-12-02 10:42:00
author: GSM 
tags: 算法
---
总结下经典的排序算法和工程中遇到的排序。
<!--more-->

# 1. 基于比较的排序算法
## 1.1 基础概述
### 1.1.1 时间复杂度$O(n^2)$ 的 排序算法

**冒泡排序** ：时间复杂度$O(n^2)$，空间复杂度：原地排序，稳定的排序算法。

**快速排序** ：时间复杂度$O(n^2)$，空间复杂度：原地排序，稳定的排序算法。

**选择排序** ：时间复杂度$O(n^2)$，空间复杂度：原地排序，不稳定的排序算法。

上述三种排序算法因为时间复杂度比较高，$O(n^2)$。因此只适合小规模数据的排序。

### 1.1.2 时间复杂度$O(nlogn)$的排序算法
对于小规模数据排序，可以使用时间复杂度$O(n^2)$的排序算法，而对于大规模数据进行排序，应该选择时间复杂度$O(nlogn)$的排序算法。

**归并排序** ：时间复杂度$O(nlogn)$，空间复杂度On, 稳定的排序算法。算法思想用到了分治思想。

缺点：实战中使用归并并不多，这是因为归并不是原地排序算法。粗略举例来说，100MB数据，除了数据本身占用的内存之外，排序算法那还需要额外占用100MB的内存，空间耗费翻倍。

一些使用归并算法解决问题的例子：
1. 有 10 个接口访问日志文件，每个日志文件大小约 300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这 10 个较小的日志文件，合并为 1 个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有 1GB，你有什么好的解决思路，能“快速”地将这 10 个日志文件合并 -- **多路归并**。

**快速排序**： 时间复杂度 $O(nlogn)$，原地排序，不稳定的排序算法。

谈谈快排的优化，快排可能导致性能差的几点：

快排性能脆弱点1：分区哨兵点选择，哨兵点选择不对可能时间复杂度退化为$O(n^2)$。 快速排序性能关键点在于 <font color="#FF6100">pivot分区哨兵点选择</font>。如果数据原来就是有序，每次pivot分区哨兵点都选择最后一个数据，那么快排时间复杂度退化为$O(n^2)$。 最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。常用的分区点选择算法：
1. 三数取中法。从区间的首、尾、中间分别取一个数，然后对比大小，取这三个数的中间值作为分区点。
2. 随机法。随机选择一个元素作为分区点，从概率的角度来看这种要好一些。

快排性能脆弱点2：快排依赖了递归，警惕堆栈溢出。解决办法：
- 限制递归深度，一旦超过设定的阈值，就停止递归；
- 在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的现在。

一些使用快速排序算法解决问题的例子：如何在$O(n)$的时间复杂度内查找一个无序数组中的第K大元素。

**堆排序**

### 1.1.3 线性时间的排序算法

## 使用场景之C语言的qsort()
C语言的qsort() : 
1. 当数据小的时候使用**归并排序**；
2. 当数据大的时候使用**快速排序**。并且选择分区点的方法就是三数取中法。qsort()自己实现了一个堆，手动模拟递归，避免递归太深导致的堆栈溢出。
3. 并且当要排序的区间元素个数<=4的时候，qsort()就退化为**插入排序**，不再使用递归做快排。(对于小规模数据的排序，O(n2) 的排序算法并不一定比 $O(nlogn)$排序算法执行的时间长。对于小数据量的排序，就选择比较简单、不需要递归的插入排序算法。)
4. 插入排序使用了哨兵做优化，少了一次判断。

## 使用场景之Java的Arrays.sort()
Java的Arrays.sort()主要使用了[双轴快速排序（by Vladimir Yaroslavskiy, Jon Bentley, and Joshua Bloch)](https://www.cnblogs.com/nullzx/p/5880191.html)，算法时间复杂度$O(nlogn)$。算法性能强于单哨兵的快排。但是并非单纯使用了一种算法就解决了所有排序问题，而是根据具体数组的情况采用合适的算法实现。

算法原理：
- 待排序元素length < 47， 使用插入排序；
- 待排序元素length < 286，使用双轴快速排序；
- 待排序元素length > 286, 检测数组的连续升序和连续降序性好不好，如果好的话就选择TimSort算法（（一种改进的归并排序算法），不好的话使用双轴快速排序。

可以看出整体思路与c语言的qsort()大致相同。

# MySQL的排序
一句话概括：
1. 当内存放得下待排序数据（待排序数据小于sort_buffer_size时候），使用**快速排序**；
2. 当内存放不下，就使用**归并排序算法**外部排序临时文件。
3.如果是Top-K场景并且没有超过K个数据大小没超过sort_buffer_size还会使用**优先队列排序算法**，利用堆来线性时间取Top-K优化性能, 并且不需要临时文件。

具体还会根据select 的字段长度，避免内存装不下，分为了全字段排序和row id排序。rowid排序可以一次排序更多行，但是要回表取数据。

MySQL做排序是一个成本比较高的操作，涉及到内存是否可以放下待排序数据，回表等问题。因此，更多时候可以利用覆盖索引技巧避免执行排序。

# Redis的ZSET排序
借助了跳表的数据结构实现了排序和$O(logn)$查找，跳表维持数据的动态插入和删除时间复杂度也是$O(logn)$。

之所以选择跳表这个数据结构。是因为Redis ZSET核心操作主要有下面这几个：
- 插入/删除/查找一个数据 
- 按照区间查找数据
    + 对于按照区间查找数据这个操作，跳表可以做到$O(logn)$ 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做相比于红黑树会非常高效。
另外，Redis之所以使用跳表实现有序结合，还有其他原因，比如跳表容易实现，更加灵活。
























